{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Notebook: Protocol-Controlled Value Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Experiment Summary](#Experiment-Summary)\n",
    "* [Experiment Assumptions](#Experiment-Assumptions)\n",
    "* [Experiment Setup](#Experiment-Setup)\n",
    "* [Analysis 1: FEI Volatile Liquidity Pool Leverage](#Analysis-1:-FEI-Volatile-Liquidity-Pool-Leverage)\n",
    "* [Analysis 2: PCV at Risk for Stable Backing Ratio Targets](#Analysis-2:-PCV-at-Risk-for-Stable-Backing-Ratio-Targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Summary \n",
    "\n",
    "The purpose of this notebook is to illustrate and evaluate the effect of a target Stable Backing Ratio and Contractionary Monetary Policy applied to Liquidity Pool protocol-owned liquidity on key system dynamics and KPIs.\n",
    "\n",
    "# Experiment Assumptions\n",
    "\n",
    "See [assumptions document](../../ASSUMPTIONS.md) for further details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Setup\n",
    "\n",
    "We begin with several experiment-notebook-level preparatory setup operations:\n",
    "\n",
    "* Import relevant dependencies\n",
    "* Import relevant experiment templates\n",
    "* Create copies of experiments\n",
    "* Configure and customize experiments \n",
    "\n",
    "Analysis-specific setup operations are handled in their respective notebook sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the setup module:\n",
    "# * sets up the Python path\n",
    "# * runs shared notebook configuration methods, such as loading IPython modules\n",
    "import setup\n",
    "\n",
    "import copy\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import experiments.notebooks.visualizations as visualizations\n",
    "from experiments.run import run\n",
    "from experiments.utils import display_code\n",
    "from experiments.notebooks.helpers.system_metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import lt, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Plotly\n",
    "import plotly.io as pio\n",
    "png_renderer = pio.renderers[\"png\"]\n",
    "png_renderer.width = 1200\n",
    "png_renderer.height = 500\n",
    "# png_renderer.scale = 1\n",
    "\n",
    "pio.renderers.default = \"png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable/disable logging\n",
    "logger = logging.getLogger()\n",
    "logger.disabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import experiment templates\n",
    "import experiments.default_experiment as default_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simulation for each analysis\n",
    "simulation_1 = copy.deepcopy(default_experiment.experiment.simulations[0])\n",
    "simulation_2 = copy.deepcopy(default_experiment.experiment.simulations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configuration\n",
    "# simulation_1.model.initial_state.update({})\n",
    "# simulation_1.model.params.update({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 1: FEI Volatile Liquidity Pool Leverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis serves to answer the what-if question: What leverage effect does protocol-owned liquidity have on total FEI supply and collateralization of the protocol in different market trends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis-specific setup\n",
    "simulation_1.engine.drop_substeps = True\n",
    "\n",
    "simulation_1.model.params.update({\n",
    "    \"liquidity_pool_tvl\": np.linspace(start=10e6, stop=200e6, num=3),\n",
    "    \"capital_allocation_fei_deposit_variables\": [\n",
    "        [\n",
    "            # Toggle on / off to isolate effect of user capital allocation for liquidity provision\n",
    "            \"fei_liquidity_pool_user_deposit\",\n",
    "            \"fei_money_market_user_deposit\",\n",
    "            \"fei_savings_user_deposit\",\n",
    "            \"fei_idle_user_deposit\",\n",
    "        ]\n",
    "    ]\n",
    "})\n",
    "\n",
    "simulation_1.model.params[\"liquidity_pool_tvl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment execution\n",
    "df_1, exceptions = run(simulation_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The liquidity pool TVL initial state was swept over three values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = df_1.plot(y=\"liquidity_pool_tvl\", color=\"subset\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Liquidity Pool Total Value Locked (TVL) Over Time\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"TVL (USD)\",\n",
    "    legend=dict(\n",
    "        title=\"Subset\",\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single stochastic Volatile Asset price realisation was used with a negative trend to simulate a bearish market:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = df_1.plot(y=\"volatile_asset_price\", color=\"subset\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Volatile Asset Price Over Time\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Volatile Asset Price (USD)\",\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The change in volatility with increased liquidity is more pronounced when looking at the constant product invariant, and the invariant drives a number of the metrics that follow. The change in volatility of the invariant is specifically caused by the movement of liquidity in and out of the pool by user FEI capital allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = df_1.plot(y=\"liquidity_pool_invariant\", color=\"subset\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Liquidity Pool Invariant Over Time\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Invariant (FEI * Volatile Asset Balance)\",\n",
    "    legend=dict(\n",
    "        title=\"Subset\",\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a specific change in volatile asset price - the larger the invariant, the larger the pool imbalance and resulting minting and redemption required to rebalance the pool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = df_1.query('timestep < 30').plot(y=\"fei_minted_redeemed\", color=\"subset\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Liquidity Pool FEI Minted (+ve) / Redeemed (-ve) Over Time\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"FEI Minted / Redeemed (FEI)\",\n",
    "    legend=dict(\n",
    "        title=\"Subset\",\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The volatility in total FEI supply due to arbitrage minting and redemption is more pronounced for deeper liquidity pools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[\"total_fei_supply_norm\"] = df_1[\"total_fei_supply\"] / df_1.groupby(\"subset\")[\"total_fei_supply\"].transform('first')\n",
    "\n",
    "fig = df_1.plot(y=\"total_fei_supply_norm\", color=\"subset\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Normalised Total FEI Supply Over Time\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Normalised Total FEI Supply (Unitless)\",\n",
    "    legend=dict(\n",
    "        title=\"Subset\",\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[\"total_fei_supply_std\"] = df_1[\"total_fei_supply\"].rolling(30).std(ddof=0)\n",
    "\n",
    "fig = df_1.plot(y=\"total_fei_supply_std\", color=\"subset\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Total FEI Supply Standard Deviation Over Time\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Standard Deviation (FEI)\",\n",
    "    legend=dict(\n",
    "        title=\"Subset\",\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the FEI and Volatile Asset liquidity pool balances move in opposite directions and with greater covariance the larger the constant product invariant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.groupby(\"subset\")[[\"fei_liquidity_pool_pcv_deposit_balance\", \"volatile_liquidity_pool_pcv_deposit_balance\"]].cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[\"fei_liquidity_pool_pcv_deposit_balance_norm\"] = (\n",
    "    df_1[\"fei_liquidity_pool_pcv_deposit_balance\"]\n",
    "    - df_1.groupby(\"subset\")[\"fei_liquidity_pool_pcv_deposit_balance\"].transform('first')\n",
    ")\n",
    "df_1[\"volatile_liquidity_pool_pcv_deposit_balance_norm\"] = (\n",
    "    df_1[\"volatile_liquidity_pool_pcv_deposit_balance\"]\n",
    "    - df_1.groupby(\"subset\")[\"volatile_liquidity_pool_pcv_deposit_balance\"].transform('first')\n",
    ")\n",
    "\n",
    "fig = df_1.plot(y=\"fei_liquidity_pool_pcv_deposit_balance_norm\", color=\"subset\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Normalised Liquidity Pool PCV Deposit FEI Balance Over Time\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Balance (FEI)\",\n",
    "    legend=dict(\n",
    "        title=\"Subset\",\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = df_1.plot(y=\"volatile_liquidity_pool_pcv_deposit_balance_norm\", color=\"subset\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Normalised Liquidity Pool PCV Deposit Volatile Asset Balance Over Time\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Balance (Volatile Asset Units)\",\n",
    "    legend=dict(\n",
    "        title=\"Subset\",\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to higher impermanent loss and leverage of deeper liquidity pools, the collateralization ratio of the protocol is negatively impacted in a market downturn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[\"collateralization_ratio_norm\"] = (\n",
    "    df_1[\"collateralization_ratio\"]\n",
    "    - df_1.groupby(\"subset\")[\"collateralization_ratio\"].transform('first')\n",
    ")\n",
    "\n",
    "fig = df_1.plot(y=\"collateralization_ratio_norm\", color=\"subset\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Normalised Collateralization Ratio Over Time\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Collateralization Ratio (%)\",\n",
    "    legend=dict(\n",
    "        title=\"Subset\",\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 2: PCV at Risk for Stable Backing Ratio Targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis serves to answer the what-if question: What effect does a PCV management strategy targetting a Stable Backing Ratio have on PCV at Risk and collateralization of the protocol? We'll statistically evaluate the efficacy of different policy settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters Sweeped:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sweep the target stable backing ratio and rebalance direction in the following way:\n",
    "- Policy 1 (bullish) - keep stable backing ratio <b>below</b> 0.3\n",
    "- Policy 2 (conservative) - keep stable backing ratio <b>above</b> 0.8\n",
    "\n",
    "Both policies are executed quarterly over the simulation. The simulation has 100 monte carlo runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_overrides = {\n",
    "    \"target_rebalancing_condition\": [gt, lt], # Simulate decrease and increase of stable backing\n",
    "    \"target_stable_backing_ratio\": [0.3, 0.8], # Simulate decrease and increase of stable backing\n",
    "    \"rebalancing_period\": [int(365/4)],  # Quarterly rebalancing\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configuration\n",
    "\n",
    "# Override default experiment number of Monte Carlo Runs\n",
    "simulation_2.runs = 100\n",
    "\n",
    "# Override default experiment System Initial State\n",
    "simulation_2.model.initial_state.update({})\n",
    "\n",
    "# Override default experiment System Parameters\n",
    "simulation_2.model.params.update(parameter_overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment execution\n",
    "df_2, exceptions = run(simulation_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volatile asset trajectories for each MC run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = df_2.query('subset == 0').plot(x='timestamp', y=['volatile_asset_price'], color='run')\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Volatile Asset Price Monte Carlo Runs Over Time\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Volatile Asset Price (USD)\",\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCV at Risk Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compute the empirical distribution of the PCV at Risk (PCVaR) KPI which will inform how likely the PCV portfolio is to lose value over a certain time horizon. For definition see docs.\n",
    "\n",
    "We set the confidence level (quantile level) at:\n",
    "$$\\alpha=0.95$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var = calculate_VaR(df_2, \"total_pcv\", alpha=alpha, timesteps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plots below we see the resulting empirical distribution of the VaR KPI for both policy settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_VaR_hist(df_var, 'VaR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_VaR_hist(df_var, 'q')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the plots, VaR in absolute terms is higher with policy 1 than with policy 2, but the quantile level of PCV returns corresponding to $\\alpha=0.95$ is higher in policy 2 than in policy 1.\n",
    "\n",
    "This is in accordance with intuition - a more conservative policy (higher stable backing) will result in less exposure to volatile asset price movements hence lower potential losses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in df_2['subset'].unique():\n",
    "    df_var_stats = df_var.query(\"subset == @subset\")[[\"VaR\", \"q\"]].describe()\n",
    "    print(f\"1-day average PCV at Risk at {100*alpha}th quantile for subset 0: \\n {df_var_stats['VaR'].loc['mean']:,.2f} USD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is of interest to compute what the likelihood of PCV at risk being greater than a certain level of returns is, to evaluate the resiliency of the policy. Here, we choose a threshold of no more than <b>1%</b> of total PCV at risk per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_return_threshold = -0.01\n",
    "q_probabilities = calculate_VaR_threshold_probability(df_var, threshold=quantile_return_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in q_probabilities.subset.unique():\n",
    "    print(f\"\"\"For Policy {subset + 1}, the 1-Day PCV at Risk is less than {abs(quantile_return_threshold*100):.2f}% with a {100*q_probabilities.query('subset == @subset')['probability'].iloc[0]:.2f}% probability\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, since policy 2 is more conservative, it is more effective in having a statistically lower value of PCVaR, implying more contained losses for the protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var_stats_0 = df_var.query(\"subset == 0\")[[\"VaR\", \"q\"]].describe()\n",
    "df_var_stats_1 = df_var.query(\"subset == 1\")[[\"VaR\", \"q\"]].describe()\n",
    "\n",
    "avg_VaR_delta = df_var_stats_0['VaR'].loc['mean'] - df_var_stats_1['VaR'].loc['mean']\n",
    "avg_VaR_quantile_delta = df_var_stats_0['q'].loc['mean'] - df_var_stats_1['q'].loc['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The Average PCVaR Delta between parameter for policies 1 and 2 is: \\n {avg_VaR_delta:,.2f} USD\")\n",
    "print(f\"The Average PCVaR Quantile Delta between parameter for policies 1 and 2 is: \\n {avg_VaR_quantile_delta:,.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to inspect specific realizations of the PCVaR KPI computed on the distributions of PCV returns across policies, the function below can be used with a certain number of runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_PCVaR_plot(df_2, df_var, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect on Collateralization Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, let us look at the dowstream effect of the target stable backing ratio policy settings on the protocol's collateralization ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = get_averages_by_subset(df_2, ['collateralization_ratio_pct']).plot(\n",
    "    y='collateralization_ratio_pct',\n",
    "    color='subset'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Collateralization Ratio\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Collateralization Ratio (%)\",\n",
    "    legend=dict(\n",
    "        title=\"Subset\",\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above we see the average collateralization ratio evolution over 100 monte carlo runs for both policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1, mu2 = compute_means(df_2, 'collateralization_ratio')\n",
    "sr1, sr2 = compute_sr(df_2, 'collateralization_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mu1 >= mu2\n",
    "prob = a.sum()/len(a)\n",
    "\n",
    "b = sr1 >= sr2\n",
    "prob2 = b.sum()/len(b)\n",
    "\n",
    "print('The empirical probability of Collateralization Ratio being higher on average with policy 1 than policy 2 is', 100*prob,'%')\n",
    "print('The empirical probability of Collateralization Ratio Sharpe being higher with policy 1 than policy 2 is', 100*prob2,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compute the probability that, averaged over all monte carlo runs, the mean collateralization ratio is higher in one policy compared to another. We also compute a metric for risk-adjusted return, the sharpe ratio.\n",
    "\n",
    "As can be seen, with the volatile exposure policy, collateralization ratio is on average higher than with the conservative policy, however its sharpe ratio is <b>never</b> higher (0% probability). This means that when taking risk into consideration, the conservative policy is more effective virtually all the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this analysis we see how the PCVaR KPI can be leveraged in gauging the statistical soundness of PCV Management for different KPI targets.\n",
    "\n",
    "Here we expressly chose to compare a very volatile-exposed policy to a highly conservative one, in line with FEI's recent FIPs, to illustrate clear-cut results which under multiple facets all point to the recommendation of the conservative policy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CADLabs Fei Model)",
   "language": "python",
   "name": "python-cadlabs-fei"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
