{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Notebook: FEI Ecosystem Model Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Experiment Summary](#Experiment-Summary)\n",
    "* [Experiment Assumptions](#Experiment-Assumptions)\n",
    "* [Experiment Setup](#Experiment-Setup)\n",
    "* [Analysis 1: ...](#Analysis-1:-...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Summary \n",
    "\n",
    "The purpose of this notebook is to assess the impact that various settings of the ETH price trajectory process have on the main elements of the FEI ecosystem model. \n",
    "\n",
    "User FEI Capital Allocation across Liquidity Pool, Money Market, and FEI Savings Deposits.\n",
    "\n",
    "# Experiment Assumptions\n",
    "\n",
    "See [assumptions document](../../ASSUMPTIONS.md) for further details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Setup\n",
    "\n",
    "We begin with several experiment-notebook-level preparatory setup operations:\n",
    "\n",
    "* Import relevant dependencies\n",
    "* Import relevant experiment templates\n",
    "* Create copies of experiments\n",
    "* Configure and customize experiments \n",
    "\n",
    "Analysis-specific setup operations are handled in their respective notebook sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the setup module:\n",
    "# * sets up the Python path\n",
    "# * runs shared notebook configuration methods, such as loading IPython modules\n",
    "import setup\n",
    "\n",
    "import copy\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "import experiments.notebooks.visualizations as visualizations\n",
    "from experiments.run import run\n",
    "from experiments.utils import display_code\n",
    "\n",
    "from experiments.notebooks.helpers.system_metrics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import lt, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "png_renderer = pio.renderers[\"png\"]\n",
    "png_renderer.width = 1200\n",
    "png_renderer.height = 500\n",
    "# png_renderer.scale = 1\n",
    "\n",
    "pio.renderers.default = \"png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable/disable logging\n",
    "logger = logging.getLogger()\n",
    "logger.disabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import experiment templates\n",
    "import experiments.default_experiment as default_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 1: Effect of Volatile Asset Trajectory on Main KPIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FEI ecosystem model is strongly driven by the Volatile Asset price process - mimicking the dependency on the Ethereum price which avenues of FEI and PCV have in the ecosystem.\n",
    "\n",
    "In this analysis we look at the effect of setting the volatile asset trajectory in three ways:\n",
    "- As a linear constant process with stochastic variation \n",
    "- As a linear uptrend process with stochastic variation \n",
    "- As a linear downtrend process with stochastic variation \n",
    "\n",
    "We look at the effect this has on the main ecosystem dynamics in absence of specific monetary policy actions taken by protocol governance, and evaluate downstream effects on mechanism-specific metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simulation for each analysis\n",
    "simulation_1 = copy.deepcopy(default_experiment.experiment.simulations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_deposits = [\n",
    "    \"fei_liquidity_pool_user_deposit\",\n",
    "    \"fei_money_market_user_deposit\",\n",
    "    \"fei_savings_user_deposit\",\n",
    "    \"fei_idle_user_deposit\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_overrides = {\n",
    "#     \"target_rebalancing_condition\": [gt, lt], # Simulate decrease and increase of stable PCV\n",
    "#     \"target_stable_pcv_ratio\": [0.2, 0.5], # Simulate decrease and increase of stable PCV\n",
    "#     \"rebalancing_period\": [int(365 / 4)],\n",
    "#     \"yield_withdrawal_period\": [999],  # Disable yield-withdrawal policy\n",
    "#     \"yield_reinvest_period\": [999],  # Disable yield-reinvestment policy\n",
    "    \"capital_allocation_fei_deposit_variables\": [\n",
    "            cam_deposits,\n",
    "    ],\n",
    "    \"capital_allocation_rebalance_duration\": [30],\n",
    "    \"fei_savings_rate_process\": [\n",
    "#          lambda _run, timestep: 0.01,\n",
    "          lambda _run, timestep: 0.03,\n",
    "#         lambda _run, timestep: 0.01 if timestep < 365 / 4 else (0.03 if timestep < 365 * 3/4 else 0.01),\n",
    "    ],\n",
    "    \"volatile_asset_price_process\": [\n",
    "        lambda _run, timestep: 2_000 + gen_norm_rv(timestep, 1, 30),\n",
    "        # lambda _run, timestep: 2_000 if timestep < 365 / 4 else (1_000 if timestep < 365 * 3/4 else 2_000),\n",
    "        lambda _run, timestep: 2_000 * (1 + timestep * 0.2 / 365) + gen_norm_rv(timestep, 1, 30),\n",
    "        lambda _run, timestep: 2_000 * (1 - timestep * 0.2 / 365) + gen_norm_rv(timestep, 1, 30),\n",
    "    ],\n",
    "    \"target_stable_backing_ratio\": [0.05], #DEBUG - does not work with 0 or None\n",
    "    \"target_rebalancing_condition\": [lt],\n",
    "    \"rebalancing_period\": [int(365/4)], # Set to > timesteps to disable policy\n",
    "    \"yield_withdrawal_period\": [int(365/4)],  # Toggle manually between policies in state update blocks\n",
    "    \"yield_reinvest_period\": [int(365/4)],\n",
    "    #\"money_market_utilization_rate_process\": [\n",
    "    #    lambda _run, timestep: 0.7, #+ gen_norm_rv(timestep, 0, 0.01),\n",
    "    #]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configuration\n",
    "\n",
    "# Override default experiment number of Monte Carlo Runs\n",
    "simulation_1.runs = 1\n",
    "\n",
    "# Override default experiment System Initial State\n",
    "simulation_1.model.initial_state.update({})\n",
    "\n",
    "# Override default experiment System Parameters\n",
    "simulation_1.model.params.update(parameter_overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis-specific setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment execution\n",
    "df, exceptions = run(simulation_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of parameter sweep:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sweep the volatile asset trajectory process for three trends - constant, downtrend, and uptrend, corresponding to stylized market conditions of a sideways, bear, and bull market respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='timestamp', y=['volatile_asset_price'], color='subset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key KPI analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = [key + '_balance' for key in cam_deposits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_dict = get_fn_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Collateralization Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: see what this looks like for < 1 -> reduce total PCV value or initial amounts of FEI\n",
    "# NICE to have: be able to toggle this from notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = get_averages_by_subset(df, ['collateralization_ratio']).plot(\n",
    "    #x='timestep',\n",
    "    y='collateralization_ratio',\n",
    "    color='subset'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Collateralization Ratio\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Collateralization Ratio\",\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metric_set_for_variable(df, fn_dict, 'collateralization_ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Stable Backing Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: policy disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = get_averages_by_subset(df, ['stable_backing_ratio']).plot(\n",
    "    #x='timestep',\n",
    "    y='stable_backing_ratio',\n",
    "    color='subset'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Stable Backing Ratio\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Stable Backing Ratio\",\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metric_set_for_variable(df, fn_dict, 'stable_backing_ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Stable PCV Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: policy disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = get_averages_by_subset(df, ['stable_pcv_ratio']).plot(\n",
    "    #x='timestep',\n",
    "    y='stable_pcv_ratio',\n",
    "    color='subset'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Stable PCV Ratio\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Stable Backing Ratio\",\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metric_set_for_variable(df, fn_dict, 'stable_pcv_ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Total PCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: policy disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = get_averages_by_subset(df, ['total_pcv']).plot(\n",
    "    #x='timestep',\n",
    "    y='total_pcv',\n",
    "    color='subset'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Total PCV\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Total PCV\",\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metric_set_for_variable(df, fn_dict, 'total_pcv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Total User-Circulating FEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = get_averages_by_subset(df, ['total_user_circulating_fei']).plot(\n",
    "    #x='timestep',\n",
    "    y='total_user_circulating_fei',\n",
    "    color='subset'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Total User Circulating FEI\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Total User Circulating FEI\",\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metric_set_for_variable(df, fn_dict, 'total_user_circulating_fei')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Circulating FEI Constituents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look into the constituents of User-Circulating FEI as a result of FEI Capital Allocation Model movements (expanded upon in analysis X (TODO: link))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User FEI Liquidity Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = get_averages_by_subset(df, ['fei_liquidity_pool_user_deposit_balance']).plot(\n",
    "    #x='timestamp',\n",
    "    y='fei_liquidity_pool_user_deposit_balance',\n",
    "    color='subset',\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='User FEI Liquidity Pool Balance',\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"User FEI LP Balance\",\n",
    "\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metric_set_for_variable(df, fn_dict, 'fei_liquidity_pool_user_deposit_balance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User FEI Money Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = get_averages_by_subset(df, ['fei_money_market_user_deposit_balance']).plot(\n",
    "    #x='timestamp',\n",
    "    y='fei_money_market_user_deposit_balance',\n",
    "    color='subset',\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='User FEI Money Market Balance',\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"User FEI MM Balance\",\n",
    "\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metric_set_for_variable(df, fn_dict, 'fei_money_market_user_deposit_balance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User FEI Savings Deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = get_averages_by_subset(df, ['fei_savings_user_deposit_balance']).plot(\n",
    "    #x='timestep',\n",
    "    y='fei_savings_user_deposit_balance',\n",
    "    color='subset',\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='User FEI Savings Deposit Balance',\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"User FEI SD Balance\",\n",
    "\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metric_set_for_variable(df, fn_dict, 'fei_savings_user_deposit_balance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Idle FEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = get_averages_by_subset(df, ['fei_idle_user_deposit_balance']).plot(\n",
    "    #x='timestep',\n",
    "    y='fei_idle_user_deposit_balance',\n",
    "    color='subset',\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='User FEI Savings Idle Balance',\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"User FEI Idle Balance\",\n",
    "\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metric_set_for_variable(df, fn_dict, 'fei_savings_user_deposit_balance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanism-Specific KPIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we focus on relevant state variables which encompass the dynamics of the stylized mechanisms in which FEI is deployed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Money markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: draw conclusion based on inclusion of dependent MM rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_averages_by_subset(df, ['fei_money_market_utilization']).plot(\n",
    "    #x='timestamp',\n",
    "    y=['fei_money_market_utilization'],\n",
    "    color='subset'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metric_set_for_variable(df, fn_dict, 'fei_money_market_utilization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_averages_by_subset(df, ['fei_money_market_borrowed']).plot(\n",
    "    #x='timestamp',\n",
    "    y=['fei_money_market_borrowed'],\n",
    "    color='subset'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metric_set_for_variable(df, fn_dict, 'fei_money_market_borrowed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_averages_by_subset(df, ['fei_money_market_supply_rate', 'fei_money_market_borrow_rate']).plot(\n",
    "    #x='timestamp',\n",
    "    y=['fei_money_market_supply_rate', 'fei_money_market_borrow_rate'],\n",
    "    color='subset'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metric_set_for_variable(df, fn_dict, 'fei_money_market_supply_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metric_set_for_variable(df, fn_dict, 'fei_money_market_borrow_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. FEI-Volatile Asset Liquidity Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: explain how this is calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_averages_by_subset(df, ['fei_liquidity_pool_user_deposit_yield_rate']).plot(\n",
    "    #x='timestamp',\n",
    "    y=['fei_liquidity_pool_user_deposit_yield_rate'],\n",
    "    color='subset'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metric_set_for_variable(df, fn_dict, 'fei_liquidity_pool_user_deposit_yield_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. FEI Savings Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: explain what it is and how it affects the rest of the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('run==1').plot(x='timestamp', y=['fei_savings_rate'], color='subset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. FEI Issuance/Leverage (minting and redemption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: TBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. PCV Yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generalize from 'subset == 0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=df.query('subset==0').volatile_yield_bearing_pcv_deposit_yield_accrued, name=\"Volatile deposit yield-bearing yield accrued\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=df.query('subset==0').volatile_idle_pcv_deposit_balance, name=\"Volatile deposit idle balance\"),\n",
    "    secondary_y=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df.timestamp, y=df.query('subset==0').volatile_yield_bearing_pcv_deposit_yield_value, name=\"Volatile deposit yield-bearing yield value\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df.timestamp, y=df.query('subset==0').volatile_idle_pcv_deposit_asset_value, name=\"Volatile deposit idle value\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"USD Value of Yield-Bearing Volatile Deposit Balance and Yield Value\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"USD Value of Deposit Balance and Yield\",\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=675,\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.99,\n",
    "        xanchor=\"right\",\n",
    "        x=0.92\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title='Timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 2: Effect of PCV Management on CR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FEI ecosystem model is strongly driven by the Volatile Asset price process - mimicking the dependency on the Ethereum price which avenues of FEI and PCV have in the ecosystem.\n",
    "\n",
    "In this analysis we look at the effect of setting the volatile asset trajectory in three ways:\n",
    "- As a linear constant process with stochastic variation \n",
    "- As a linear uptrend process with stochastic variation \n",
    "- As a linear downtrend process with stochastic variation \n",
    "\n",
    "We look at the effect this has on the main ecosystem dynamics in absence of specific monetary policy actions taken by protocol governance, and evaluate downstream effects on mechanism-specific metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simulation for each analysis\n",
    "simulation_2 = copy.deepcopy(default_experiment.experiment.simulations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_deposits = [\n",
    "    \"fei_liquidity_pool_user_deposit\",\n",
    "    \"fei_money_market_user_deposit\",\n",
    "    \"fei_savings_user_deposit\",\n",
    "    \"fei_idle_user_deposit\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_overrides = {\n",
    "#     \"target_rebalancing_condition\": [gt, lt], # Simulate decrease and increase of stable PCV\n",
    "#     \"target_stable_pcv_ratio\": [0.2, 0.5], # Simulate decrease and increase of stable PCV\n",
    "#     \"rebalancing_period\": [int(365 / 4)],\n",
    "#     \"yield_withdrawal_period\": [999],  # Disable yield-withdrawal policy\n",
    "#     \"yield_reinvest_period\": [999],  # Disable yield-reinvestment policy\n",
    "    \"capital_allocation_fei_deposit_variables\": [\n",
    "            cam_deposits,\n",
    "    ],\n",
    "    \"capital_allocation_rebalance_duration\": [30],\n",
    "    \"fei_savings_rate_process\": [\n",
    "#          lambda _run, timestep: 0.01,\n",
    "          lambda _run, timestep: 0.03,\n",
    "#         lambda _run, timestep: 0.01 if timestep < 365 / 4 else (0.03 if timestep < 365 * 3/4 else 0.01),\n",
    "    ],\n",
    "#     \"volatile_asset_price_process\": [\n",
    "#         lambda _run, timestep: 2_000 + gen_norm_rv(timestep, 1, 30),\n",
    "#         # lambda _run, timestep: 2_000 if timestep < 365 / 4 else (1_000 if timestep < 365 * 3/4 else 2_000),\n",
    "#         lambda _run, timestep: 2_000 * (1 + timestep * 0.2 / 365) + gen_norm_rv(timestep, 1, 30),\n",
    "#         lambda _run, timestep: 2_000 * (1 - timestep * 0.2 / 365) + gen_norm_rv(timestep, 1, 30),\n",
    "#     ],\n",
    "    \"target_rebalancing_condition\": [gt, lt], # Simulate decrease and increase of stable PCV\n",
    "    # Disable policy by setting to None\n",
    "    \"target_stable_pcv_ratio\": [None], # Simulate decrease and increase of stable PCV\n",
    "    \"target_stable_backing_ratio\": [0.3, 0.8], # Simulate decrease and increase of stable backing\n",
    "    \"rebalancing_period\": [int(365/4)], # Set to > timesteps to disable policy\n",
    "    \"yield_withdrawal_period\": [int(365/4)],  # Toggle manually between policies in state update blocks\n",
    "    \"yield_reinvest_period\": [int(365/4)],\n",
    "    #\"money_market_utilization_rate_process\": [\n",
    "    #    lambda _run, timestep: 0.7, #+ gen_norm_rv(timestep, 0, 0.01),\n",
    "    #]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configuration\n",
    "\n",
    "# Override default experiment number of Monte Carlo Runs\n",
    "simulation_2.runs = 100\n",
    "\n",
    "# Override default experiment System Initial State\n",
    "simulation_2.model.initial_state.update({})\n",
    "\n",
    "# Override default experiment System Parameters\n",
    "simulation_2.model.params.update(parameter_overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis-specific setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment execution\n",
    "df2, exceptions = run(simulation_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_means(df, variable):\n",
    "    \n",
    "    \n",
    "    n_runs = len(df['run'].value_counts())\n",
    "    \n",
    "    mu1, mu2 = [], []\n",
    "    \n",
    "    for run in range(1,n_runs+1):\n",
    "        diff = (df.query('subset == 0 and run==@run')[variable] -\n",
    "                df2.query('subset == 1 and run==@run')[variable])\n",
    "        \n",
    "        s1 = df.query('subset == 0 and run==@run')[variable]\n",
    "        s2 = df.query('subset == 1 and run==@run')[variable]\n",
    "        \n",
    "        mu1.append(s1.mean())#/s1.std())\n",
    "        mu2.append(s2.mean())#/s2.std())\n",
    "        \n",
    "    return np.array(mu1), np.array(mu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sr(df, variable):\n",
    "    \n",
    "    \n",
    "    n_runs = len(df['run'].value_counts())\n",
    "    \n",
    "    mu1, mu2 = [], []\n",
    "    \n",
    "    for run in range(1,n_runs+1):\n",
    "        diff = (df.query('subset == 0 and run==@run')[variable] -\n",
    "                df2.query('subset == 1 and run==@run')[variable])\n",
    "        \n",
    "        r1 = df.query('subset == 0 and run==@run')[variable]#.pct_change()\n",
    "        r2 = df.query('subset == 1 and run==@run')[variable]#.pct_change()\n",
    "        \n",
    "        mu1.append(r1.mean()/r1.std())\n",
    "        mu2.append(r2.mean()/r2.std())\n",
    "        \n",
    "    return np.array(mu1), np.array(mu2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.query('subset == 0').plot(x='timestamp', y=['volatile_asset_price'], color='run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = get_averages_by_subset(df2, ['collateralization_ratio']).plot(\n",
    "    #x='timestep',\n",
    "    y='collateralization_ratio',\n",
    "    color='subset'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Collateralization Ratio\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Collateralization Ratio\",\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.98,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1, mu2 = compute_means(df2, 'collateralization_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr1, sr2 = compute_sr(df2, 'collateralization_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mu1 >= mu2\n",
    "prob = a.sum()/len(a)\n",
    "\n",
    "print('The empirical probability of CR being higher on average with policy 1 than policy 2 is', prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = sr1 >= sr2\n",
    "prob = b.sum()/len(b)\n",
    "\n",
    "print('The empirical probability of CR Sharpe being higher with policy 1 than policy 2 is', prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([mu1, mu2]).T.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([sr1, sr2]).T.hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCV at Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_VaR(df, state_variable, alpha, timesteps):\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    for simulation in df.simulation.unique():\n",
    "        df_simulation = df.query(\"simulation == @simulation\")\n",
    "        for subset in df_simulation.subset.unique():\n",
    "            df_subset = df_simulation.query(\"subset == @subset\")\n",
    "            for run in df_subset.run.unique():\n",
    "                df_run = df_subset.query(\"run == @run\")\n",
    "\n",
    "                returns = df_run[state_variable].pct_change()\n",
    "                final_value = df_run[state_variable].iloc[-1]\n",
    "                q = returns.quantile(1 - alpha)\n",
    "                value_at_risk = abs(final_value * q) * np.sqrt(timesteps)\n",
    "\n",
    "                result = pd.DataFrame({'simulation': [simulation], 'subset': [subset], 'run': [run], 'VaR': [value_at_risk], 'q': [q]})\n",
    "                results = pd.concat([results, result])\n",
    "\n",
    "    return results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_VaR_threshold_probability(df, threshold):\n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    for subset in df.subset.unique():\n",
    "        df_subset = df.query(\"subset == @subset\")\n",
    "        \n",
    "        df_threshold = df_subset[\"q\"] >= threshold\n",
    "        probability = df_threshold.sum() / len(df_threshold)\n",
    "        \n",
    "        result = pd.DataFrame({'subset': [subset], 'threshold': [threshold], 'probability': [probability]})\n",
    "        results = pd.concat([results, result])\n",
    "    \n",
    "    return results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_to_plot(df, run, subset):\n",
    "    pcv_ret = df.query('run == @run and subset == @subset')['total_pcv'].pct_change()\n",
    "    var = df_var.query('run == @run and subset == @subset')['VaR'].iloc[0]\n",
    "    q = df_var.query('run == @run and subset == @subset')['q'].iloc[0]\n",
    "    \n",
    "    return pcv_ret, var, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_VaR_hist(df_var, variable):\n",
    "    df_ = pd.concat(\n",
    "        [\n",
    "            df_var.query('subset==0')[variable].reset_index(drop=True),\n",
    "            df_var.query('subset==1')[variable].reset_index(drop=True),\n",
    "        ], axis=1)\n",
    "\n",
    "    df_.columns = [variable+'_0', variable+'_1']\n",
    "    \n",
    "    return df_.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var = calculate_VaR(df2, \"total_pcv\", alpha=0.95, timesteps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var.query(\"subset == 0\")[[\"VaR\", \"q\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var.query(\"subset == 1\")[[\"VaR\", \"q\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_VaR_hist(df_var, 'VaR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_VaR_hist(df_var, 'q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var_stats_0 = df_var.query(\"subset == 0\")[[\"VaR\", \"q\"]].describe()\n",
    "df_var_stats_1 = df_var.query(\"subset == 1\")[[\"VaR\", \"q\"]].describe()\n",
    "\n",
    "print(f\"1-day average PCV at Risk at 95th quantile for subset 0: \\n {df_var_stats_0['VaR'].loc['mean']:,.2f} USD\")\n",
    "print(f\"1-day average PCV at Risk at 95th quantile for subset 1: \\n {df_var_stats_1['VaR'].loc['mean']:,.2f} USD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_return_threshold = -0.01\n",
    "q_probabilities = calculate_VaR_threshold_probability(df_var, threshold=quantile_return_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in q_probabilities.subset.unique():\n",
    "    print(f\"\"\"For Policy {subset + 1}, the 1-Day PCV at Risk is less than {abs(quantile_return_threshold*100):.2f}% with a {100*q_probabilities.query('subset == @subset')['probability'].iloc[0]:.2f}% probability\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_VaR_delta = df_var_stats_0['VaR'].loc['mean'] - df_var_stats_1['VaR'].loc['mean']\n",
    "avg_VaR_quantile_delta = df_var_stats_0['q'].loc['mean'] - df_var_stats_1['q'].loc['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The Average PCVaR Delta between parameter for policies 1 and 2 is: \\n {avg_VaR_delta:,.2f} USD\")\n",
    "print(f\"The Average PCVaR Quantile Delta between parameter for policies 1 and 2 is: \\n {avg_VaR_quantile_delta:,.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=6, cols=2,\n",
    "                    x_title='PCV Daily Returns - Left: Policy 0, Right: Policy 1',\n",
    "                    y_title='Number of Observations',\n",
    "                   )\n",
    "\n",
    "for subset in [0, 1]:\n",
    "    for run in range(1,7):\n",
    "\n",
    "        pcv_ret, var, q = get_data_to_plot(df2, run, subset)\n",
    "\n",
    "        fig.add_trace(\n",
    "            px.histogram(pcv_ret, x=\"total_pcv\", nbins=100).data[0],\n",
    "            row=run, col=subset+1)\n",
    "\n",
    "        fig.add_vline(x=q, row=run, col=subset+1)\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Histogram of PCV Returns for Runs and Policy Settings\",\n",
    "    autosize=False,\n",
    "    #width=1200,\n",
    "    height=1600,\n",
    ")\n",
    "\n",
    "#fig.update_xaxes(xaxis_title='a')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f'1-Day PCVar for Run 1, Policy 0 (Subset 0) is {var:,.2f} USD with 5% quantile value {100*q:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whats the probability that the state variable has a volatility greater than x for this policy setting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whats the probability that the state variable falls below x for this policy setting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whats the probability that the state variable ends up at at least x for this policy setting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the probability that CR >= 1? VA price analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import wilcoxon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = wilcoxon(mu1, mu2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diff_tstat(df, variable):\n",
    "    \n",
    "    D = dict()\n",
    "    \n",
    "    n_runs = len(df['run'].value_counts())\n",
    "    \n",
    "    for run in range(1,n_runs+1):\n",
    "        diff = (df.query('subset == 0 and run==@run')[variable] -\n",
    "                df2.query('subset == 1 and run==@run')[variable])\n",
    "        \n",
    "        mu1 = df.query('subset == 0 and run==@run')[variable].mean()\n",
    "        mu2 = df.query('subset == 1 and run==@run')[variable].mean()\n",
    "        \n",
    "        mean_diff = mu1 - mu2\n",
    "        #print('mean diff', mean_diff)\n",
    "\n",
    "        diff_std = diff.std()\n",
    "        \n",
    "        t_stat = mean_diff / (diff_std / np.sqrt(n_runs))\n",
    "        D[run] = t_stat\n",
    "        \n",
    "    return pd.DataFrame(D.values(), index=D.keys())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_diff_tstat(df2, 'collateralization_ratio')#.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('subset == 0 and run==2')['collateralization_ratio'] - df.query('subset == 1 and run==2')['collateralization_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonparametric hypothesis test:\n",
    "# statistic - difference in - collateral ratio, stable backing ratio across pairs of policies for runs\n",
    "# test: h0 Delta_v2 - Delta_v1 = 0, h1: Delta_v2 - Delta_v1 =/= 0\n",
    "# https://www.investopedia.com/terms/t/t-test.asp\n",
    "# https://machinelearningmastery.com/nonparametric-statistical-significance-tests-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
